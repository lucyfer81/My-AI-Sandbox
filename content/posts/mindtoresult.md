+++
title = '一念动，万事成。'
date = 2025-08-31T17:13:55+08:00
draft = false
+++

最近又有一个重磅级的开源项目，微软的VibeVoice。功能是文字=>语音。
有人说，这有什么了不起的，微软自己就有EdgeTTS，其他Google等也有成熟的项目免费使用。

还是很不一样的。让我来告诉你VibeVoice有哪些酷炫的特点。
1）超长上下文
2）多人语音实时轮替
3）LLM处理语境，让发声更自然，逼真。

当然，这个模型也不是随便一台家里的普通电脑，或者普通你的云服务器能够跑起来的。1.5b的模型需要24GB的显存。
如果你想在家里自己独享，你需要这样一台电脑，

配件	型号/说明	价格（元）
显卡	NVIDIA GeForce RTX 4090 24 GB（公版/华硕 TUF）<br><KIMI_REF />	11,999
CPU	Intel i5-14600KF（14 核 20 线程，足够喂饱 4090）	1,799
主板	MSI B760M Mortar DDR5 WiFi	999
内存	32 GB DDR5-6000（16 GB×2）	699
SSD	1 TB NVMe PCIe 4.0（系统+缓存）	399
电源	850 W 80+ Gold 全模组	599
机箱	中塔 + 3 把风扇	299
散热器	240 mm 一体水冷	299
合计	——	≈ 16,100 元

如果你觉得的太贵，你可以去腾讯云租一台GPU云服务器，大约19元一个小时。当然，第一个小时你基本上是在安装配置这个模型。但是接下去，你就可以以5块钱的代价生成一个小时的语音。甚至公绩云是0.4元生成一个小时的语音。

看到这你可能会问，这又怎么样？

我来告诉你这对现在的相关生态有什么影响。过去需要编剧 → 配音演员 → 录音师 → 剪辑师 → 混音师 → 发行运营，现在一个人搞定。
1）那些做早晚20分钟播报的主播，可以以极小的代价，创建自己的20分钟音频。
2）那些购买IP（小说，故事等）来自己录音的主播会受到很大的冲击，因为生产语音的代价大大降低，且大大加快。

短时间内，那些事实访谈节目，头部有特色的主播不受影响。但是依然会有三个连锁效应：

1） 创意权重 > 执行权重
谁能提出好选题、好脚本，谁就能立刻变现；执行细节被模型封装。
2） 边际成本趋零 → 长尾爆发
过去因为 ROI 太小没人做的方言评书、冷门教材、极客周报，现在都能以 2 元成本跑一条，长尾市场瞬间被填满。
3） 个人即工作室
你甚至都不需要自己有一台高配置电脑。一台普通PC➕云服务 = 一条完整生产线；
今天想做科幻短篇宇宙，明天就能切到儿童睡前故事，换赛道只需要改提示词就行了

甚至，在商业化这条路上，对广告业也会产生冲击：
1）试错成本趋零：品牌可先让 AI 播客跑 A/B 测试脚本，ROI 合格后再请真人主播拍“正式版”。
2）长尾广告位：本地餐饮、区域房地产能用“方言 AI 播客”投放，过去他们可买不起真人制作。

当然，也不尽是我说的那么完美。之前阿里就已经开源了CozyVoices模型，我们依然可以看到很多真人主播在赛场上。我们还有时间去适应，适应这个一念动，万事成的时代。


最近又有一个重磅级的开源项目，微软的VibeVoice。功能是文字=>语音。
有人说，这有什么了不起的，微软自己就有EdgeTTS，其他Google等也有成熟的项目免费使用。

还是很不一样的。让我来告诉你VibeVoice有哪些酷炫的特点。
1）超长上下文
2）多人语音实时轮替
3）LLM处理语境，让发声更自然，逼真。

当然，这个模型也不是随便一台家里的普通电脑，或者普通你的云服务器能够跑起来的。1.5b的模型需要24GB的显存。
如果你想在家里自己独享，你需要这样一台电脑，

配件	型号/说明	价格（元）
显卡	NVIDIA GeForce RTX 4090 24 GB（公版/华硕 TUF）<br><KIMI_REF />	11,999
CPU	Intel i5-14600KF（14 核 20 线程，足够喂饱 4090）	1,799
主板	MSI B760M Mortar DDR5 WiFi	999
内存	32 GB DDR5-6000（16 GB×2）	699
SSD	1 TB NVMe PCIe 4.0（系统+缓存）	399
电源	850 W 80+ Gold 全模组	599
机箱	中塔 + 3 把风扇	299
散热器	240 mm 一体水冷	299
合计	——	≈ 16,100 元

如果你觉得的太贵，你可以去腾讯云租一台GPU云服务器，大约19元一个小时。当然，第一个小时你基本上是在安装配置这个模型。但是接下去，你就可以以5块钱的代价生成一个小时的语音。甚至公绩云是0.4元生成一个小时的语音。

看到这你可能会问，这又怎么样？

我来告诉你这对现在的相关生态有什么影响。过去需要编剧 → 配音演员 → 录音师 → 剪辑师 → 混音师 → 发行运营，现在一个人搞定。
1）那些做早晚20分钟播报的主播，可以以极小的代价，创建自己的20分钟音频。
2）那些购买IP（小说，故事等）来自己录音的主播会受到很大的冲击，因为生产语音的代价大大降低，且大大加快。

短时间内，那些事实访谈节目，头部有特色的主播不受影响。但是依然会有三个连锁效应：

1） 创意权重 > 执行权重
谁能提出好选题、好脚本，谁就能立刻变现；执行细节被模型封装。
2） 边际成本趋零 → 长尾爆发
过去因为 ROI 太小没人做的方言评书、冷门教材、极客周报，现在都能以 2 元成本跑一条，长尾市场瞬间被填满。
3） 个人即工作室
你甚至都不需要自己有一台高配置电脑。一台普通PC➕云服务 = 一条完整生产线；
今天想做科幻短篇宇宙，明天就能切到儿童睡前故事，换赛道只需要改提示词就行了

甚至，在商业化这条路上，对广告业也会产生冲击：
1）试错成本趋零：品牌可先让 AI 播客跑 A/B 测试脚本，ROI 合格后再请真人主播拍“正式版”。
2）长尾广告位：本地餐饮、区域房地产能用“方言 AI 播客”投放，过去他们可买不起真人制作。

当然，也不尽是我说的那么完美。之前阿里就已经开源了CozyVoices模型，我们依然可以看到很多真人主播在赛场上。我们还有时间去适应，适应这个一念动，万事成的时代。


最近又有一个重磅级的开源项目，微软的VibeVoice。功能是文字=>语音。
有人说，这有什么了不起的，微软自己就有EdgeTTS，其他Google等也有成熟的项目免费使用。

还是很不一样的。让我来告诉你VibeVoice有哪些酷炫的特点。
1）超长上下文
2）多人语音实时轮替
3）LLM处理语境，让发声更自然，逼真。

当然，这个模型也不是随便一台家里的普通电脑，或者普通你的云服务器能够跑起来的。1.5b的模型需要24GB的显存。
如果你想在家里自己独享，你需要这样一台电脑，

配件	型号/说明	价格（元）
显卡	NVIDIA GeForce RTX 4090 24 GB（公版/华硕 TUF）<br><KIMI_REF />	11,999
CPU	Intel i5-14600KF（14 核 20 线程，足够喂饱 4090）	1,799
主板	MSI B760M Mortar DDR5 WiFi	999
内存	32 GB DDR5-6000（16 GB×2）	699
SSD	1 TB NVMe PCIe 4.0（系统+缓存）	399
电源	850 W 80+ Gold 全模组	599
机箱	中塔 + 3 把风扇	299
散热器	240 mm 一体水冷	299
合计	——	≈ 16,100 元

如果你觉得的太贵，你可以去腾讯云租一台GPU云服务器，大约19元一个小时。当然，第一个小时你基本上是在安装配置这个模型。但是接下去，你就可以以5块钱的代价生成一个小时的语音。甚至公绩云是0.4元生成一个小时的语音。

看到这你可能会问，这又怎么样？

我来告诉你这对现在的相关生态有什么影响。过去需要编剧 → 配音演员 → 录音师 → 剪辑师 → 混音师 → 发行运营，现在一个人搞定。
1）那些做早晚20分钟播报的主播，可以以极小的代价，创建自己的20分钟音频。
2）那些购买IP（小说，故事等）来自己录音的主播会受到很大的冲击，因为生产语音的代价大大降低，且大大加快。

短时间内，那些事实访谈节目，头部有特色的主播不受影响。但是依然会有三个连锁效应：

1） 创意权重 > 执行权重
谁能提出好选题、好脚本，谁就能立刻变现；执行细节被模型封装。
2） 边际成本趋零 → 长尾爆发
过去因为 ROI 太小没人做的方言评书、冷门教材、极客周报，现在都能以 2 元成本跑一条，长尾市场瞬间被填满。
3） 个人即工作室
你甚至都不需要自己有一台高配置电脑。一台普通PC➕云服务 = 一条完整生产线；
今天想做科幻短篇宇宙，明天就能切到儿童睡前故事，换赛道只需要改提示词就行了

甚至，在商业化这条路上，对广告业也会产生冲击：
1）试错成本趋零：品牌可先让 AI 播客跑 A/B 测试脚本，ROI 合格后再请真人主播拍“正式版”。
2）长尾广告位：本地餐饮、区域房地产能用“方言 AI 播客”投放，过去他们可买不起真人制作。

当然，也不尽是我说的那么完美。之前阿里就已经开源了CozyVoices模型，我们依然可以看到很多真人主播在赛场上。我们还有时间去适应，适应这个一念动，万事成的时代。

另，待我有时间，我把blog里哪篇Deepseek生成的短篇小说用Stable Diffussion 做漫画，再转成语音，做个有声漫画，一定很有意思。
